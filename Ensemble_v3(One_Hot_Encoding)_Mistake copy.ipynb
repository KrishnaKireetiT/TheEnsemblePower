{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParamClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, param_grid):\n",
    "        self.param_grid = param_grid\n",
    "        self.model = None  # Placeholder for the trained model\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, data, target_column, n_estimators=5, test_size=0.2, random_state=42):\n",
    "        # Step 1: Split dataset into features (X) and target (y)\n",
    "        X = data.drop(columns=[target_column])\n",
    "        y = data[target_column]\n",
    "\n",
    "        # Step 2: Split into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "        # Step 3: Identify categorical columns\n",
    "        self.categorical_cols_ = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        # Step 4: Fit One-Hot Encoder on training data only\n",
    "        if self.categorical_cols_:\n",
    "            self.encoder_ = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "            X_train_encoded = self.encoder_.fit_transform(X_train[self.categorical_cols_])\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            encoded_feature_names = self.encoder_.get_feature_names_out(self.categorical_cols_)\n",
    "            X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_feature_names, index=X_train.index)\n",
    "\n",
    "            # Drop categorical columns and merge encoded features\n",
    "            X_train = X_train.drop(columns=self.categorical_cols_).reset_index(drop=True)\n",
    "            X_train_encoded_df = X_train_encoded_df.reset_index(drop=True)\n",
    "            X_train = pd.concat([X_train, X_train_encoded_df], axis=1)\n",
    "\n",
    "        # Step 5: Transform X_test using the SAME encoder\n",
    "        if self.categorical_cols_:\n",
    "            X_test_encoded = self.encoder_.transform(X_test[self.categorical_cols_])\n",
    "            X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_feature_names, index=X_test.index)\n",
    "\n",
    "            # Drop categorical columns and merge encoded features\n",
    "            X_test = X_test.drop(columns=self.categorical_cols_, errors=\"ignore\").reset_index(drop=True)\n",
    "            X_test_encoded_df = X_test_encoded_df.reset_index(drop=True)\n",
    "            X_test = pd.concat([X_test, X_test_encoded_df], axis=1)\n",
    "\n",
    "        # Step 6: Ensure X_train and X_test have the SAME columns (avoid shape mismatch)\n",
    "        missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "        for col in missing_cols:\n",
    "            X_test[col] = 0  # Add missing columns in X_test\n",
    "\n",
    "        # Step 7: Fill any remaining NaN values (important to avoid errors)\n",
    "        X_train.fillna(0, inplace=True)\n",
    "        X_test.fillna(0, inplace=True)\n",
    "\n",
    "        # Reorder columns in X_test to match X_train\n",
    "        X_test = X_test[X_train.columns]\n",
    "\n",
    "        # Step 8: Generate hyperparameter combinations and train multiple Decision Trees\n",
    "        all_param_combos = list(ParameterGrid(self.param_grid))\n",
    "        np.random.shuffle(all_param_combos)\n",
    "        chosen_combos = all_param_combos[:n_estimators]\n",
    "\n",
    "        self.estimators_ = []\n",
    "        for params in chosen_combos:\n",
    "            model = DecisionTreeClassifier(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            self.estimators_.append(model)\n",
    "\n",
    "        # Store test data for future evaluation\n",
    "        self.X_test_ = X_test\n",
    "        self.y_test_ = y_test\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "    \n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # ✅ Check if categorical columns exist before encoding\n",
    "        existing_categorical_cols = [col for col in self.categorical_cols_ if col in X.columns]\n",
    "\n",
    "        if existing_categorical_cols:\n",
    "            # Apply One-Hot Encoding only if categorical columns still exist\n",
    "            X_encoded = self.encoder_.transform(X[existing_categorical_cols])\n",
    "            encoded_feature_names = self.encoder_.get_feature_names_out(existing_categorical_cols)\n",
    "            X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_feature_names, index=X.index)\n",
    "\n",
    "            # Drop original categorical columns and merge encoded features\n",
    "            X = X.drop(columns=existing_categorical_cols, errors=\"ignore\").reset_index(drop=True)\n",
    "            X_encoded_df = X_encoded_df.reset_index(drop=True)\n",
    "            X = pd.concat([X, X_encoded_df], axis=1)\n",
    "\n",
    "        # ✅ Ensure X has the same features as during training\n",
    "        missing_cols = set(self.estimators_[0].feature_names_in_) - set(X.columns)\n",
    "        for col in missing_cols:\n",
    "            X[col] = 0  # Add missing columns with 0 values\n",
    "\n",
    "        # Reorder columns to match training data\n",
    "        X = X[self.estimators_[0].feature_names_in_]\n",
    "\n",
    "        # ✅ Get predictions from all models\n",
    "        predictions = np.array([estimator.predict(X) for estimator in self.estimators_])\n",
    "\n",
    "        # ✅ Majority voting with correct shape\n",
    "        final_predictions = mode(predictions, axis=0).mode\n",
    "        return np.ravel(final_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Convert X to a DataFrame if it's not already one\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # Apply One-Hot Encoding to categorical columns (same as in fit)\n",
    "        if self.categorical_cols_:\n",
    "            X_encoded = self.encoder_.transform(X[self.categorical_cols_])\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            encoded_feature_names = self.encoder_.get_feature_names_out(self.categorical_cols_)\n",
    "            X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_feature_names, index=X.index)\n",
    "\n",
    "            # Drop original categorical columns and concatenate encoded columns\n",
    "            X = X.drop(columns=self.categorical_cols_).reset_index(drop=True)\n",
    "            X_encoded_df = X_encoded_df.reset_index(drop=True)\n",
    "            X = pd.concat([X, X_encoded_df], axis=1)\n",
    "\n",
    "        # Get predicted probabilities from all trained models\n",
    "        probas = np.array([estimator.predict_proba(X) for estimator in self.estimators_])\n",
    "\n",
    "        # Average the predicted probabilities across all models\n",
    "        final_probas = np.mean(probas, axis=0)\n",
    "        \n",
    "        return final_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (with categorical columns)\n",
    "data = pd.read_csv(\"titanic.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Model Performance 🎯\n",
      "✅ Accuracy on Test Set (Majority Voting): 0.8212\n",
      "\n",
      "🔹 Hyperparameters & Accuracy for Each Estimator:\n",
      "\n",
      "🔹 Model 1 hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n",
      "📌 Model 1 Accuracy: 0.8212\n",
      "\n",
      "🔹 Model 2 hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n",
      "📌 Model 2 Accuracy: 0.8045\n",
      "\n",
      "🔹 Model 3 hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n",
      "📌 Model 3 Accuracy: 0.8212\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ✅ Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10], \n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# ✅ Initialize classifier\n",
    "clf = HyperParamClassifier(param_grid)\n",
    "\n",
    "# ✅ Train the classifier with One-Hot Encoding applied\n",
    "clf.fit(data, target_column='Survived', n_estimators=3)\n",
    "\n",
    "# ✅ Compute ensemble accuracy using `clf.predict()`\n",
    "y_pred_ensemble = clf.predict(clf.X_test_)  # Use stored test data\n",
    "accuracy_ensemble = accuracy_score(clf.y_test_, y_pred_ensemble)\n",
    "\n",
    "# ✅ Print results\n",
    "print(\"\\n🎯 Model Performance 🎯\")\n",
    "print(f\"✅ Accuracy on Test Set (Majority Voting): {accuracy_ensemble:.4f}\")\n",
    "\n",
    "# ✅ Print hyperparameters & accuracy of each trained estimator\n",
    "print(\"\\n🔹 Hyperparameters & Accuracy for Each Estimator:\")\n",
    "for i, model in enumerate(clf.estimators_):\n",
    "    print(f\"\\n🔹 Model {i+1} hyperparameters: {model.get_params()}\")\n",
    "\n",
    "    # ✅ Ensure only existing categorical columns are used\n",
    "    existing_categorical_cols = [col for col in clf.categorical_cols_ if col in clf.X_test_.columns]\n",
    "\n",
    "    if existing_categorical_cols:\n",
    "        X_test_transformed = pd.DataFrame(\n",
    "            clf.encoder_.transform(clf.X_test_[existing_categorical_cols]),\n",
    "            columns=clf.encoder_.get_feature_names_out(existing_categorical_cols),\n",
    "            index=clf.X_test_.index\n",
    "        )\n",
    "\n",
    "        # Drop original categorical columns and merge encoded features\n",
    "        X_test_final = clf.X_test_.drop(columns=existing_categorical_cols, errors=\"ignore\").reset_index(drop=True)\n",
    "        X_test_final = pd.concat([X_test_final, X_test_transformed.reset_index(drop=True)], axis=1)\n",
    "    else:\n",
    "        X_test_final = clf.X_test_\n",
    "\n",
    "    # ✅ Make predictions for **this individual model**\n",
    "    y_pred = model.predict(X_test_final)\n",
    "\n",
    "    # ✅ Compute accuracy for the **individual model**\n",
    "    accuracy = accuracy_score(clf.y_test_, y_pred)\n",
    "\n",
    "    print(f\"📌 Model {i+1} Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
