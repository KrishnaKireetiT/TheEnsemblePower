{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including a data pre-processing method <br>\n",
    "Class inputs changed to whole dataset instead of x_train and y_train <br>\n",
    "<p>\n",
    "Preprocessing includes checking for nan-values\n",
    "filling nans with imputer\n",
    "checking for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-process method <br>\n",
    "parameters - dataset, target name, test_split = 0.2 (default), sampling = False,\n",
    "pipeline:\n",
    "missing values<br>\n",
    "train test split <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParamClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, param_grid, random_state=None, voting='hard'):\n",
    "        \n",
    "        self.param_grid = param_grid\n",
    "        self.random_state = random_state\n",
    "        self.voting = voting\n",
    "        self.estimators_ = []  # to store the trained models\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "        return X.iloc[indices], y.iloc[indices]\n",
    "\n",
    "    def fit(self, X, y, n_estimators=5):\n",
    "        \n",
    "        # Set random seed if provided for reproducibility.\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        # Generate all possible hyperparameter combinations.\n",
    "        all_param_combos = list(ParameterGrid(self.param_grid))\n",
    "        \n",
    "        # If there are fewer combinations than needed, sample with replacement;\n",
    "        # otherwise, shuffle and take the first n_estimators.\n",
    "        if len(all_param_combos) < n_estimators:\n",
    "            chosen_combos = [all_param_combos[i] for i in \n",
    "                             np.random.randint(0, len(all_param_combos), size=n_estimators)]\n",
    "        else:\n",
    "            np.random.shuffle(all_param_combos)\n",
    "            chosen_combos = all_param_combos[:n_estimators]\n",
    "        \n",
    "        self.estimators_ = []\n",
    "        for params in chosen_combos:\n",
    "            # Get a bootstrap sample from the data.\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "            # Initialize and train the decision tree on the bootstrap sample.\n",
    "            model = DecisionTreeClassifier(**params)\n",
    "            model.fit(X_sample, y_sample)\n",
    "            self.estimators_.append(model)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.voting == 'hard':\n",
    "            # Get predictions from each estimator (shape: [n_estimators, n_samples])\n",
    "            predictions = np.array([estimator.predict(X) for estimator in self.estimators_])\n",
    "            # Majority vote: compute the mode along the estimator axis and flatten to 1D.\n",
    "            majority_votes = mode(predictions, axis=0).mode.flatten()\n",
    "            return majority_votes\n",
    "        elif self.voting == 'soft':\n",
    "            # For soft voting, average predicted probabilities and take argmax.\n",
    "            avg_probas = self.predict_proba(X)\n",
    "            return np.argmax(avg_probas, axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"voting parameter must be either 'hard' or 'soft'.\")\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        probas = np.array([estimator.predict_proba(X) for estimator in self.estimators_])\n",
    "        avg_probas = np.mean(probas, axis=0)\n",
    "        return avg_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>252</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>247</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>219</td>\n",
       "      <td>232</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>221</td>\n",
       "      <td>255</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5    6    7    8    9  ...  775  776  777  778  779  780  \\\n",
       "0  0  0  0  0  0  0    0    0    0   21  ...   47    8    0    0    0    0   \n",
       "1  0  0  0  0  0  0  241  252   51    0  ...  254  247   37    0    0    0   \n",
       "2  0  0  0  0  0  0    0    0    0    0  ...    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0    0    0    0    0  ...  219  232   61    0    0    0   \n",
       "4  0  0  0  0  0  0   64  221  255  125  ...  255  115    0    0    0    0   \n",
       "\n",
       "   781  782  783  label  \n",
       "0    0    0    0      9  \n",
       "1    0    0    0      1  \n",
       "2    0    0    0      7  \n",
       "3    0    0    0      2  \n",
       "4    0    0    0      1  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (with categorical columns)\n",
    "data = pd.read_csv(\"kmnist.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20], \n",
    "    'min_samples_split': [2, 5, 7, 9, 10]\n",
    "}\n",
    "x = data.drop(\"label\", axis = 1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,stratify=y)\n",
    "\n",
    "clf = HyperParamClassifier(param_grid, random_state=42, voting='hard')\n",
    "clf.fit(x_train, y_train, n_estimators=5)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "y_proba = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.14%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{100*accuracy_score(y_test, y_pred):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
