{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemented basic voting (hard voting) <br>\n",
    "fixed the issue with predict method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParamClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, param_grid, random_state=None):\n",
    "        \n",
    "        self.param_grid = param_grid\n",
    "        self.random_state = random_state\n",
    "        self.estimators_ = []  # to store the trained models\n",
    "\n",
    "    def fit(self, X, y, n_estimators=5):\n",
    "        \n",
    "        # Set random seed if provided\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        # Generate all possible hyperparameter combinations\n",
    "        all_param_combos = list(ParameterGrid(self.param_grid))\n",
    "        \n",
    "        # If there are fewer combinations than needed, sample with replacement;\n",
    "        # otherwise, shuffle and take the first n_estimators.\n",
    "        if len(all_param_combos) < n_estimators:\n",
    "            chosen_combos = [all_param_combos[i] for i in \n",
    "                             np.random.randint(0, len(all_param_combos), size=n_estimators)]\n",
    "        else:\n",
    "            np.random.shuffle(all_param_combos)\n",
    "            chosen_combos = all_param_combos[:n_estimators]\n",
    "        \n",
    "        self.estimators_ = []\n",
    "        for params in chosen_combos:\n",
    "            model = DecisionTreeClassifier(**params)\n",
    "            model.fit(X, y)\n",
    "            self.estimators_.append(model)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # Get predictions from each estimator\n",
    "        predictions = np.array([estimator.predict(X) for estimator in self.estimators_])\n",
    "        # Majority vote (mode) along the ensemble axis (axis=0)\n",
    "        majority_votes = mode(predictions, axis=0).mode\n",
    "        return majority_votes\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        # Get probability predictions from each estimator\n",
    "        probas = np.array([estimator.predict_proba(X) for estimator in self.estimators_])\n",
    "        # Average the probabilities over all models\n",
    "        avg_probas = np.mean(probas, axis=0)\n",
    "        return avg_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>252</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>247</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>219</td>\n",
       "      <td>232</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>221</td>\n",
       "      <td>255</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5    6    7    8    9  ...  775  776  777  778  779  780  \\\n",
       "0  0  0  0  0  0  0    0    0    0   21  ...   47    8    0    0    0    0   \n",
       "1  0  0  0  0  0  0  241  252   51    0  ...  254  247   37    0    0    0   \n",
       "2  0  0  0  0  0  0    0    0    0    0  ...    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0    0    0    0    0  ...  219  232   61    0    0    0   \n",
       "4  0  0  0  0  0  0   64  221  255  125  ...  255  115    0    0    0    0   \n",
       "\n",
       "   781  782  783  label  \n",
       "0    0    0    0      9  \n",
       "1    0    0    0      1  \n",
       "2    0    0    0      7  \n",
       "3    0    0    0      2  \n",
       "4    0    0    0      1  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (with categorical columns)\n",
    "data = pd.read_csv(\"kmnist.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20], \n",
    "    'min_samples_split': [2, 5, 7, 9, 10]\n",
    "}\n",
    "x = data.drop(\"label\", axis = 1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,stratify=y)\n",
    "\n",
    "clf = HyperParamClassifier(param_grid, random_state=42)\n",
    "clf.fit(x_train, y_train, n_estimators=3)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "y_proba = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.03%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{100*accuracy_score(y_test, y_pred):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import mode\n",
    "\n",
    "# # Simulate predictions from 3 estimators for 10 test samples\n",
    "# n_estimators = 3\n",
    "# n_samples = 10\n",
    "# # For demonstration, let's assume a binary classification problem (classes 0 and 1)\n",
    "# np.random.seed(42)\n",
    "# predictions = np.random.randint(0, 2, size=(n_estimators, n_samples))\n",
    "# print(\"Predictions from each estimator:\\n\", predictions)\n",
    "\n",
    "# # Compute majority vote (mode) along axis=0\n",
    "# majority_votes = mode(predictions, axis=0).mode.flatten()\n",
    "# print(\"Ensemble's majority votes:\\n\", majority_votes)\n",
    "\n",
    "# # Visualize the predictions for a specific sample (e.g., sample index 3)\n",
    "# sample_index = 3\n",
    "# sample_preds = predictions[:, sample_index]\n",
    "\n",
    "# # Get counts for each predicted class for this sample\n",
    "# classes, counts = np.unique(sample_preds, return_counts=True)\n",
    "\n",
    "# # Create a bar chart showing the votes\n",
    "# plt.figure(figsize=(6,4))\n",
    "# plt.bar(classes, counts, color='skyblue', edgecolor='black')\n",
    "# plt.xlabel(\"Predicted Class\")\n",
    "# plt.ylabel(\"Vote Count\")\n",
    "# plt.title(f\"Votes for Test Sample {sample_index}\\nMajority Vote: {majority_votes[sample_index]}\")\n",
    "# plt.xticks(classes)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create a small dataset\n",
    "# data = pd.DataFrame({\n",
    "#     'X1': [1, 2, 3, 4],\n",
    "#     'X2': [2, 3, 4, 5]\n",
    "# })\n",
    "# y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# print(\"Original Data:\")\n",
    "# print(data)\n",
    "# print(\"Labels:\", y)\n",
    "\n",
    "# # Number of bootstrap samples (models) we want to generate\n",
    "# n_bootstrap = 3\n",
    "# n_samples = len(data)\n",
    "\n",
    "# bootstrap_samples = []\n",
    "\n",
    "# # Generate bootstrap samples\n",
    "# for i in range(n_bootstrap):\n",
    "#     indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "#     sample = data.iloc[indices].reset_index(drop=True)\n",
    "#     sample_y = y[indices]\n",
    "#     bootstrap_samples.append((indices, sample, sample_y))\n",
    "#     print(f\"\\nBootstrap sample {i+1}:\")\n",
    "#     print(\"Indices:\", indices)\n",
    "#     print(\"Sample:\\n\", sample)\n",
    "#     print(\"Labels:\", sample_y)\n",
    "\n",
    "# # For demonstration, let's simulate predictions from each model for 10 test samples.\n",
    "# # Suppose each model returns a prediction (0 or 1) for each test sample.\n",
    "# # Here, we simulate by randomly generating predictions.\n",
    "# n_test = 10\n",
    "# np.random.seed(42)\n",
    "# # Each model makes predictions for n_test samples; shape: (n_bootstrap, n_test)\n",
    "# predictions = np.random.randint(0, 2, size=(n_bootstrap, n_test))\n",
    "# print(\"\\nPredictions from each model:\")\n",
    "# print(predictions)\n",
    "\n",
    "# # Use majority voting (mode) for each test sample\n",
    "# from scipy.stats import mode\n",
    "# ensemble_predictions = mode(predictions, axis=0).mode.flatten()\n",
    "\n",
    "# print(\"\\nEnsemble predictions (by majority vote):\")\n",
    "# print(ensemble_predictions)\n",
    "\n",
    "# # Visualize the predictions for one test sample, say sample index 3\n",
    "# sample_index = 3\n",
    "# sample_preds = predictions[:, sample_index]\n",
    "# classes, counts = np.unique(sample_preds, return_counts=True)\n",
    "\n",
    "# plt.figure(figsize=(6,4))\n",
    "# plt.bar(classes, counts, color='skyblue', edgecolor='black')\n",
    "# plt.xlabel(\"Predicted Class\")\n",
    "# plt.ylabel(\"Vote Count\")\n",
    "# plt.title(f\"Votes for Test Sample {sample_index}\\nMajority Vote: {ensemble_predictions[sample_index]}\")\n",
    "# plt.xticks(classes)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
